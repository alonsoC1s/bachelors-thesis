La tésis se enfoca en explorar y explicar que transformaciones se pueden aplicar a los problemas de optimización en programación dinámica que definen al problema de RL para convertirlos a problemas más fáciles computacionalmente.

Posible título: The Reinforcement Learning Problem through the lens of optimization theory.

El enfoque hasta ahora en la parte teórica es desarrollar con cuidado cómo se aproxima la solución a un problema de programación dinámica mediante programación lineal iterada. Esa idea la saqué de el curso _Graduate Artificial Intelligence 15-780_ de Zico Kolter impartido en Carnegie Mellon en 2016. En particular de [[kolter2014lecture]].

*Importante:* Trato de codificar todos los documentos y/o fuentes con el mismo código que uso para BibLaTeX

## Posibles lugares donde está resuleto el problema:

- Curso _Graduate Artificial Intelligence 15-780_ de Zico Kolter:
- En el 2014 hay lectures [grabados](http://www.cs.cmu.edu/~zkolter/course/15-780-s14/lectures.html).
- En el 2016 hay [notas](http://www.cs.cmu.edu/afs/cs/academic/class/15780-s16/www/slides/mdps.pdf), que estoy usando [[kolter2014lecture]].
- La página de [David Silver](https://www.davidsilver.uk/teaching/). En particular, Lecture 3: [Planning by Dynamic Programming](https://www.davidsilver.uk/wp-content/uploads/2020/03/DP.pdf) [[silver2015lecture]].
- El curso en [MITOCW](https://ocw.mit.edu/courses/mechanical-engineering/2-997-decision-making-in-large-scale-systems-spring-2004/index.htm)  _Decision Making in Large Scale Systems_ impartido por la profesora Pucci De Farias, quien escribió _[[farias2003LP2ADP]]_.
- El [dissertations](http://web.mit.edu/~pucci/www/daniela_thesis.pdf) de Danieala P. De Farias [[farias2002thesis]] que trata el mismo tema que el artículo.
- Capítulos 3, 4 & 5 de [[sutton2020reinforcement]]. Podrían tener un approach mucho más simple y fácil de usar en la tesis.