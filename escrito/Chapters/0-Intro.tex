In the last 20 or so years a number of advancements and novel 
techniques have transformed the landscape of the discipline we 
currently call Artificial Intelligence. These new approaches have made 
possible tasks deemed intractable decades prior, such as natural 
language processing, image recognition and machine learning, to name a 
few. These advancements have come of a fruitful synergy between 
several fields of study: Mathematics and Computer Science to be 
precise.

As these techniques have moved from being the \textit{state of the 
art} to becoming mostly a problem of engineering, most of the people 
currently implementing solutions based on Artificial Intelligence 
today have little to no knowledge of the mathematical underpinnings 
that enable such powerful methods, for they do not need it to do their 
job.  This thesis represents an effort to explore the theory and 
intuitions behind one of the most innovative techniques in Artificial 
Intelligence: Reinforcement Learning. The aim of this work is to 
explore the key ideas in the areas of mathematics that provide the 
foundations for Reinforcement Learning: Stochastic Processes, 
Probability Theory, and a special emphasis on Mathematical 
Optimization, so the field and problems can be presented in an 
engaging fashion while sacrificing as little clarity as possible.  
Then, some selected problems and applications will be presented to 
illustrate the power of the techniques the reader has become 
acquainted to. 

As a mathematician I feel a special obligation to share the beauty of 
the ideas in our field to those outside of it. To that end and to make 
this work more enjoyable to the people I dedicate it to, I try to 
emulate a more leisurely style than the one found in research papers.  
Some terseness will be sacrificed in favor of clarity. Nevertheless, 
the mathematical minutia will not be ``swept under the rug'' or 
separated from the main body of text. Instead I will try to give 
context to the development of mathematical ideas, while not insisting 
on subjecting the reader to every single technical detail necessary 
for the formality of the arguments. The involved details will be 
available to those curious in appendixes.

This thesis consists of mainly three parts and several chapters that 
make up said parts. The first part presents the main ideas from the 
different fields of mathematics that will be needed to motivate and 
justify the theory behind Reinforcement Learning. The second part 
explores the Reinforcement Learning problems as the matter of 
Mathematics, and in particular how are these problems solved through 
different techniques in optimization. The third and final part deals 
with applications of Reinforcement Learning.

Interspersed among the purely mathematical theory are examples of how 
are these ideas expressed in the \href{https://julialang.org/}{Julia 
Programming Language}. These code snippets will be mostly self 
contained, ready to run, and leverage the vast ecosystem that makes 
Julia ideal for Mathematics and Scientific disciplines. Some code 
examples will play the role of pseudo code as Julia's simple syntax 
allows the mathematical ideas to shine through the implementation 
details.
