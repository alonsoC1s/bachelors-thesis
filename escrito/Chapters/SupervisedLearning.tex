In Chapter \ref{chapter:Motivation} we gave a brief review of the areas that
constitute the field of Machine Learning, and motivated an introductory example
to Reinforcement Learning. We highlighted the differences to Supervised Machine
Learning (supervised ML) by contrasting the way each work: supervised ML recives
a wealth of examples from which it must extract patters, while RL receives no
input data and so has to learn by interacting with its environment. Supervised
ML is often tasked with classifying or predicting a response. In this thesis we
focus only on the classification task.

\section{Classification}
Supervised ML algorithms tasked with classifying recive large amounts of
labelled data. Through the process called ``fitting'' or ``learning'', the
algorithm will (hopefully) label correctly new observations never seen before.
The classification task seeks to find a systematic way of predicting a
phenomenon given a set of measurements.

\subsection{Formalizing}
Putting some concepts to work, picture a scenario where we have access to
several measurements (e.g. age, weight, blood pressure, etc\dots) for a group of
patients. Some proportion of the patients in the study group suffered a stroke,
the rest did not. Our task is to find a systematic way of predicting whether or
not a new patient not studied before will suffer from a stroke by measuring the
same variables measured for the initial group.

Fundamentally, a supervised ML algorithm must first of all receive a
\textit{training set}, a set of pre-labelled data from a knowledgeable source; in
contrast with RL, where labelling is often not even possible or practical. This
source of truth, the training set, is a set of observations $(\vec{x}_1, y_1),
\dots, (\vec{x}_n, y_n)$. The vectors $\vec{x}_i = [x_1, x_2, \dots, x_p]^{\top}
\in \R^{p}$ can be thought of as a list of measurements of every variable of
interest for the $i$-th observation. In the case of the example trying to
predict strokes, $x_1$ would correspond to age, $x_2$ to weight, and so on. The
training set also contains $y_1, \dots, y_n$, one-dimensional values we call
variables or labels in the specific case of classification. Using the standard
parlance, following \cite{louppe2014}, the input variables are known as
\textit{features}, input vectors as \textit{instances} or \textit{samples} and
the output variable as \textit{target}. For our purposes we consider that the
target variable is always categoric, not numeric or continuous. Nevertheless,
continuous target variables are allowed, but the learning task is called
regression, which is outside of scope for this thesis.

In a typicall ML workflow the algorithm that will be used to make predictions is
trained on the set we just described, and it's performance tested on a different
set of similar data that the algorithm had no access to during its training
period. From now on, we denote the training set as $\L$. For convenience we
group the feature vectors into a \textit{feature matrix} $X \in \R^{p \times
n}$, where the $i$-th column is $\vec{x}_i$. Similarly, we group the target
variables into the vector $\vec{y} \in \R^{n}$.

Our classification task can be framed as finding a function $f_{\L}$ we will
call model whose output or predictions $f_{\L} (\vec{x}) = \widehat{\vec{y}}$ are
``as good as possible''. We subscript the function $f$ with $\L$ to highlight the
fact that the function is dependent on what data the learning set contains. We
proceed to define what makes a model ``good'' at making predictions.

\subsection{Evaluation}
As it has become a recurring theme in this thesis,
determining what makes a prediction good and finding the best possible model
$f_\L$ is a process of optimization. Since we assume that the learning set is a
sample of the population we aim to label with our model, it stands to reason
that a model that makes the fewest mistakes when tasked with classifiying the
training observations will also make the fewest mistakes when classifiying new
observations. In reality that is not exactly the case, as often making the
number of classification mistakes as small as possible in the training set
results in a model that ``memorized'' the set and has no ability whatsoever to
generalize patterns, it only reproduces known-good answers. But the idea is not
entirely misguided, it provides a good starting point.

% The process we referred to as ``fitting'' a model consists of minimizing the number of misclassifications in the training set. We refer to this the expected number of misclassifications on the training set as the training error.

% \begin{dfn}{Training Error}{training-error}
%     The classification error function describes the expected number of erroneous
%     classifications made by the model $f_{\L}$ on the training set $\L$.
%     \begin{equation*}
%         \Err (f_\L) \coloneqq \frac{1}{n} \sum_{i = 1}^{n} \1(y_i \neq \widehat{y}_i),
%     \end{equation*}
%     where $\widehat{y}_i \coloneqq f_\L (\vec{x}_i)$ is the prediction of the
%     model for the $i$-th observation. The symbol $\1$ refers to the indicator
%     function which equals 1 whenever the condition inside holds and 0 otherwise.
% \end{dfn}

The process we referred to as ``fitting'' a model consists of finding a model
which minimizes its expected prediction error.

\begin{dfn}{Prediction or Generalization Error}{generalization-error}
    The expected \emph{prediction} or \emph{generalization} error of a model
    $f_\L$ is the probability of misclassification of the model
    \begin{equation*}
        \Err (f_\L) = \mathbb{E} \left[ \1 (y_i \neq \widehat{y}_i)  \right].
    \end{equation*}
    Where $\widehat{y}_i \coloneqq f_\L (\vec{x}_i)$ is the model's prediction
    for the observation $\vec{x}_i$.
\end{dfn}

Minimizing this Generalization Error will allow us to classify the most new
observatins commiting as the lowest possible number of errors overall. This
includes observations never seen before, not only the ones we have acces to in
the training set. Since the distributions for observations $(\vec{x}_j, y_j)$
are generally not known the generalization error must be estimated. Several
techniques to solve this problem exist, but are numerous and outside of scope.
From now on we denote $\widehat{\Err}$ an estimator of the generalization error.

The term ``fitting'' when talking about finding a suitable model is a
consequence of how such model is found. Since the generalization error is not
directly measurable and thus not directly minimizable, we have to use a
reasonable approximation. We assume that a family of candidate models,
$\mathcal{H}$ known as hypotheses, exists. Our optimization target then becomes
to find the best model among the space of hypotheses. To be more specific, let
$\vec{\theta}$ be the vector of hyper-parameters controlling the behaviour of a
specific model. Then, our optimization task is to find $\theta^{*}$,
\begin{equation*}
    \theta^{*} \coloneqq \argmin_{\theta} \widehat{\Err}(f_\L (\vec{x}; \theta)) \quad \forall \vec{x}.
\end{equation*}

A myriad of classification models are available, each leveraging different
properties and resulting in different strengths and weaknesses. The optimization
problem involved in fitting each one is different from the rest. For the
purposes of this thesis we focus on one specific model: classification trees. We
introduce them here and show in part II how fitting them gives way to an
optimization process analogous to a Reinforcement Learning problem, and frame it
as such so we can leverage the power of RL to fit classification trees.

\section{Classification Trees}
Classification trees and, more generally, classification and regression trees,
are Machine Learning models as the ones described in the previous section. They
have gained massive popularity in the recent and ongoing boom in Machine
Learning for their numerous qualities. For instance, they can model arbitrarily
complex relationships in data, handle both numeric and categorical data, and are
easily interpretable as they result in simple decision rules. Most importantly,
they are the building block of the state-of-the art algorithms for ML such as
XGBoost \cite{XGBoost}.

Sadly, their fitting process leads to a rather complicated problem that cannot
be solved exactly in a reasonable time. The fitting process shares many
similarities with the RL problem, which is described in wealth of detail in
Chapter \ref{chapter:ReinforcementLearning}. This similarity is the foundational
idea of this thesis, and we hope to show in part II how an alternative
methodology to fitting trees can be developed by leveraging the techniques used
in RL. With that goal in mind, it is time to lay the foundations of the
structure behind trees.

\subsection{Tree models}
Let $\Omega = \left\{ (\vec{x}_i, y_i) \right\}$ be the space of all possible
feature-target pairs. When each feature $y$ is part of a set of categories
$\mathcal{C} \coloneqq \left\{ c_1, c_2, \dots, c_j \right\}$, another way to
look at the classification task is to define a partion over $\Omega$ taking
advantage of the natural distinction our set of categories provide.
\begin{equation*}
    \Omega = \bigcup_{i=1}^{j} \Omega_{c_i},
\end{equation*}
where each $\Omega_{c_i}$ is defined as $\left\{ (\vec{x}_k, y_k) \mid y_k = c_k
\right\}$.

Similarly, a model $f_\L$ defines a partition. This partition however is made
over the input space $\mathcal{X} = \left\{ \vec{x}_i \mid (\vec{x}_i, y_i) \in
\Omega \right\}$. This partition can be described as the preimages of $f_\L$ as
such
\begin{equation*}
    \mathcal{X} = \bigcup_{i=1}^{j} f_{\L}^{-1}(\Omega_{c_i}).
\end{equation*}
The classification task then, can be tought of, as learning the model $f_\L$
that gives the partion of $\mathcal{X}$ that most closely approximates the
partion on $\Omega$ as a result of it's preimages.

In other words, we are trying to represent $f$ as a tree (in the same way
Computer Science thinks about trees) where any node $t$ represents a subspace
$\mathcal{X}_t \subseteq \mathcal{X}$ of the input space such that the node
designated as root (denoted $t_0$) correspondes to the entirety of
$\mathcal{X}$. Internal nodes $t$ are originated via a \textit{split} $s_t$
taken from a set of question $\mathcal{Q}$.

The set of questions $\mathcal{Q}$ is just what it sounds like. The question
defining split $s_t$ might be, for example, is $x_m < 65$? Or, is the person
recorded as observation $m$ younger than 65 years old? The space $\mathcal{X}_t$
represented by node $t$ is made up of disjoint subspaces corresponding to each
of $t$'s children nodes; two in the case of binary trees. 

Terminal nodes (or leaves) are labelled with a a best guess value $\widehat{y}_t
\in \mathcal{C}$. The prediction process is carried out by navigating the tree,
providing answers to the questions defining each node, until a leaf is reached.
The label for that leaf will be the tree's prediction. In algorithm
\ref{alg:tree-predict} we show a formal description of the process.

\begin{algorithm}
    \SetKwFunction{Predict}{predict}
    \KwIn{The tree $f_\L$}
    \KwIn{The feature vector $\vec{x}$}
    \KwOut{The predicted class $\widehat{y}$ for $\vec{x}$}
    \Function{\Predict{$f_\L, \vec{x}$}}{
        $t \gets t_0$ \;
        \While{$t$ is not a terminal node}{
            $t \gets$ the child node $t'$ of $t$ such that $\vec{x} \in \mathcal{X}_t$ \;
        }
        \Return{$\widehat{y}_t$} \;
    }
    \caption{Prediction of the output value $\widehat{y}$ from tree $f_\L$.}
    \label{alg:tree-predict}
\end{algorithm}

[Maybe una imágen de muestra de el árbol particionando el espacio.]

\subsection{Fitting Decission Trees}