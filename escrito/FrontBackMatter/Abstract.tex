\addcontentsline{toc}{chapter}{Abstract}

\chapter*{Resumen}
En las últimas décadas, avances en el campo conocido como Inteligencia
Artificial nos han forzado a revaluar problemas que antres se creían
prácticamente imposibles de resolver mediante el uso de computadoras. Problemas
como procesamiento de lenguaje natural, reconocimiento de imágenes y otros,
considerados hace unas décadas imposibles, ahora es posible resolver y son
utilizados en nuestro día a día. Estos avances se han dado gracias a la sinergia
entre las Matemáticas y las Ciencias de la Computación.

Estas herramientas pasaron de ser problemas teóricos estudiados en la
a\-ca\-de\-mi\-a, a ser problemas de ingeniería que se resuelven a escala día
tras día. Una gran parte de las personas involucradas en la implementación de
estas soluciones tienen conocimiento limitado sobre los conceptos matemáticos
que subyacen la práctica que llevan a cabo, lo cual es natural dado que no es
conocimiento esencial para sus tareas cotidianas. Esta tesis es un esfuerzo por
explorar la teoría y las intuiciones detrás de una de las técnicas más novedosas
de la Inteligencia Artificial: Aprendizaje por Refuerzo (\textsc{rl} por sus
siglas en inglés). Esta tesis busca sentar las bases en Procesos Estocásticos,
Probabilidad, y Optimización que dan el trasfondo para entender el aprendizaje
por refuerzo. Se busca presentar el contenido de manera intuitiva sin dejar de
lado el rigor matemático. Como matemático siento una obligación por presentar el
campo de estudio con la belleza que percibimos quienes lo estudiamos.

Esta tesis está compuesta por capítulos divididos en tres partes. La primera
parte presenta las ideas fundamentales de los diferentes campos de las
matemáticas que son esenciales para el aprendizaje por refuerzo, y una corta
introducción al campo del aprendizaje de máquina supervisado. La segunda parte
presenta en concreto lo que llamaremos el \emph{problema de aprendizaje por
refuerzo} en términos de un problema matemático, y desarrollamos la teoría que
permite dar soluciones aproximadas a este problema explicando porqué son de
interés. La tercera y última parte establece la conexión entre el aprendizaje de
máquina supervisado y el aprendizaje por refuerzo, y propone un algoritmo basado
en las soluciones aproximadas, que son el foco principal de esta tesis, al
problema de ajuste de árboles de decisión. Finalmente se sientan las bases con
ejemplos de código que podrían facilitar una futura implementación completa del
algoritmo que se propone.

\chapter*{Abstract}
In the last 20 or so years, several advancements and novel
techniques have transformed the landscape of the discipline we currently call
Artificial Intelligence. These new approaches have made possible tasks that were
deemed intractable decades prior, such as natural language processing, image
recognition, and human-level competence at certain games, to name a few. These
advancements have come from a fruitful synergy between several fields of study:
Mathematics and Computer Science, to be precise.

As these techniques have moved from being the \textit{state of the art} to
mainly becoming a problem of engineering, most of the people currently
implementing solutions based on Artificial Intelligence today have limited
knowledge of the mathematical underpinnings that enable such powerful methods,
for they do not need it to do their job. This thesis represents an effort to
explore the theory and intuitions behind one of the most innovative techniques
in Artificial Intelligence: \acf{rl}. This work aims to explore the key ideas in
the areas of mathematics that provide the foundations for Reinforcement
Learning: Stochastic Processes, Probability Theory, and a particular emphasis on
Mathematical Optimization, so the field and problems can be presented in an
engaging fashion while sacrificing as little clarity as possible.

This thesis consists of mainly three parts, and several chapters that make up
said parts. The first part, presents the main ideas from the different fields of
mathematics that will be needed to motivate and justify the theory behind
\ac{rl}, along with a brief introduction to the field of Supervised Machine
Learning. The second part develops the titular component of this thesis:
approximate solutions to the Reinforcement Learning Problem, motivating reasons
why approximations are desireable. Lastly, the third part motivates the framing
of an important problem in Supervised Machine Learning, the fitting of decision
trees, as a Reinforcement Learning Problem and proposes an algorithm based on
the approximate solutions developed earlier. We conclude by implementing the
elemental building blocks that would be needed to provide a complete
implementation of the propose algorithm in the future.