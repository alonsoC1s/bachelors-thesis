
@article{bellman1957,
  title = {A {{Markovian Decision Process}}},
  author = {Bellman, Richard},
  date = {1957},
  journaltitle = {Journal of Mathematics and Mechanics},
  volume = {6},
  number = {5},
  eprint = {24900506},
  eprinttype = {jstor},
  pages = {679--684},
  publisher = {{Indiana University Mathematics Department}},
  issn = {0095-9057}
}

@article{Blaom2020,
  title = {{{MLJ}}: {{A Julia}} Package for Composable Machine Learning},
  author = {Blaom, Anthony D. and Kiraly, Franz and Lienart, Thibaut and Simillides, Yiannis and Arenas, Diego and Vollmer, Sebastian J.},
  date = {2020},
  journaltitle = {Journal of Open Source Software},
  volume = {5},
  number = {55},
  pages = {2704},
  publisher = {{The Open Journal}},
  doi = {10.21105/joss.02704},
  url = {https://doi.org/10.21105/joss.02704}
}

@book{breiman2017,
  title = {Classification {{And Regression Trees}}},
  author = {Breiman, Leo},
  date = {2017-10-24},
  publisher = {{Routledge}},
  location = {{New York}},
  doi = {10.1201/9781315139470},
  abstract = {The methodology used to construct tree structured rules is the focus of this monograph. Unlike many other statistical procedures, which moved from pencil and},
  isbn = {978-1-315-13947-0},
  pagetotal = {368}
}

@article{denardo1970,
  title = {On {{Linear Programming}} in a {{Markov Decision Problem}}},
  author = {Denardo, Eric V.},
  date = {1970},
  journaltitle = {Management Science},
  volume = {16},
  number = {5},
  eprint = {2628518},
  eprinttype = {jstor},
  pages = {281--288},
  publisher = {{INFORMS}},
  issn = {0025-1909},
  abstract = {This paper treats a Markov decision problem with an infinite planning horizon and no discounting. This model is analyzed by application, perhaps repeated, of a simple linear program.}
}

@article{depenoux1963,
  title = {A {{Probabilistic Production}} and {{Inventory Problem}}},
  author = {D'\'Epenoux, Fran\c{c}ois},
  date = {1963},
  journaltitle = {Management Science},
  volume = {10},
  number = {1},
  eprint = {2627210},
  eprinttype = {jstor},
  pages = {98--108},
  publisher = {{INFORMS}},
  issn = {0025-1909}
}

@book{elements2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  date = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/978-0-387-84858-7},
  url = {http://link.springer.com/10.1007/978-0-387-84858-7},
  urldate = {2022-09-01},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  keywords = {Averaging,Boosting,classification,clustering,data mining,machine learning,Projection pursuit,Random Forest,supervised learning,Support Vector Machine,unsupervised learning}
}

@thesis{farias2002thesis,
  type = {phdthesis},
  title = {The {{Linear Programming Approach}} to {{Approximate Dynamic Programming}}: {{Theory}} and {{Application}}},
  author = {family=Pucci, given=family=Farias, suffix=prefix=De, prefix=given=Daniela, useprefix=true},
  date = {2002},
  institution = {{Stanford University}}
}

@article{farias2003LP2ADP,
  title = {The {{Linear Programming Approach}} to {{Approximate Dynamic Programming}}},
  author = {family=Pucci, given=family=Farias, suffix=prefix=De, prefix=given=Daniela, useprefix=true and Van Roy, Benjamin},
  date = {2003},
  journaltitle = {Operations Research},
  volume = {51},
  number = {6},
  pages = {850--865},
  publisher = {{INFORMS}},
  issn = {0030364X, 15265463}
}

@article{hyafil1976,
  title = {Constructing Optimal Binary Decision Trees Is {{NP-complete}}},
  author = {Hyafil, Laurent and Rivest, Ronald L.},
  date = {1976-05-01},
  journaltitle = {Information Processing Letters},
  shortjournal = {Information Processing Letters},
  volume = {5},
  number = {1},
  pages = {15--17},
  issn = {0020-0190},
  doi = {10.1016/0020-0190(76)90095-8},
  url = {https://www.sciencedirect.com/science/article/pii/0020019076900958},
  urldate = {2022-09-06},
  abstract = {When ontologies reach a certain size and complexity, faults such as inconsistencies, unsatisfiable classes or wrong entailments are hardly avoidable. Locating the incorrect axioms that cause these faults is a hard and time-consuming task. Addressing this issue, several techniques for a semi-automatic fault localization in ontologies have been proposed and extensively studied. One class of these approaches involve a human expert who provides answers to system-generated queries about the intended (correct) ontology in order to reduce the possible fault locations. To suggest as informative questions as possible, existing methods draw on various algorithmic optimizations as well as heuristics. However, these computations are often based on certain assumptions about the interacting expert. In this work, we demonstrate that these assumptions might not always be adequate and discuss consequences of their violations. In particular, we characterize a range of expert types with different query answering behavior and show that existing approaches are far from achieving optimal efficiency for all of them. In addition, we find that the cost metric adopted by state-of-the-art techniques might not always be realistic and that a change of metric has a decisive impact on the best choice of query answering strategy. As a remedy, we suggest a new \textendash{} and simpler \textendash{} type of expert question that leads to a stable fault localization performance for all analyzed expert types and effort metrics, and has numerous further advantages over existing techniques. Moreover, we present an algorithm which computes and optimizes this new query type in worst-case polynomial time and which is fully compatible with existing concepts (e.g., query selection heuristics) and infrastructure (e.g., debugging user interfaces) in the field. Comprehensive experiments on faulty real-world ontologies attest that the new querying method is substantially and statistically significantly superior to existing techniques both in terms of the number of necessary expert interactions and in terms of the query computation time. We find that relying on the new querying method can save an interacting expert more than 80\% of their work, and can reduce the expert's waiting time for the next query by more than three orders of magnitude. Beside these findings, we demonstrate that the efficiency of existing query-based tools can be significantly boosted by suggesting an appropriate query answering strategy to an expert; we also make recommendations in this regard. Further, we suggest optimal configurations of a debugger for situations where the new type of query is used. Remarkably, the proposed approach is not only applicable to ontologies, but to any monotonic knowledge representation language, and can even be adopted to solve general model-based diagnosis problems expressible using Reiter's theory. In recent years, the uptake of Artificial Intelligence (AI) in industry is increasing. For many AI techniques, like Deep Learning, optimization, planning, etc., computational and storage requirements are significant. The problem of determining what is the right hardware (HW on premise or on the cloud) architecture and its dimensioning for AI algorithms is still crucial. Searching for the optimal solution is often challenging, as it is not trivial to anticipate the behavior of an algorithm on diverse architectures. This is especially true if the AI application must respect quality-of-service constraints or budgets. In this scenario, having an automated decision support tool to match algorithms, user constraints and HW resources would be a great advantage for companies and practitioners working with AI applications. In this paper, we tackle this challenge with an approach that relies on the Empirical Model Learning paradigm, based on the integration of Machine Learning (ML) models into an optimization problem. The key idea is to integrate domain knowledge held by experts with data-driven models that learn the relationships between HW requirements and AI algorithm performances. In particular, the approach starts with benchmarking multiple AI algorithms on different HW resources, generating data used to train ML models; then, optimization is used to find the best HW configuration that respects user-defined constraints (e.g., budget, time, solution quality). In the experimental evaluation we validate our approach on a complex problem, namely online algorithms for energy systems, an area characterized by uncertainty and tight HW and real-time constraints. Results show the effectiveness of our approach and its flexibility: We can train the ML models only once and reuse them in the optimization model to tackle a variety of problems, determined by different data instances and user-defined constraints. Decision tree induction is a simple, however powerful learning and classification tool to discover knowledge from the database. The volume of data in databases is growing to quite large sizes, both in the number of attributes and instances. Some important limitations of decision trees are instability, local decisions, and overfitting for this extensive data. The simple, effective and non-convergence nature of the African Buffalo Optimization (ABO) algorithm makes it suitable to solve complex optimization problems. In this paper, we propose the African Buffalo Optimized Decision Tree (ABODT) algorithm to create globally optimized decision trees using the intelligent and collective behaviour of African Buffalos. The modified African Buffalo optimization algorithm is used to create efficient and optimal decision trees. To evaluate the efficiency of the proposed African Buffalo Optimized Decision Tree algorithm, experiments are performed on 15 standard UCI learning repository datasets that are of various sizes and domains. Results show that the African Buffalo Optimized Decision Tree algorithm globally optimizes decision trees, increases accuracy and reduces the size of a decision tree. These optimized trees are stable and efficient than conventional decision trees. In this paper, we model an optimal regression tree through a continuous optimization problem, where a compromise between prediction accuracy and both types of sparsity, namely local and global, is sought. Our approach can accommodate important desirable properties for the regression task, such as cost-sensitivity and fairness. Thanks to the smoothness of the predictions, we can derive local explanations on the continuous predictor variables. The computational experience reported shows the outperformance of our approach in terms of prediction accuracy against standard benchmark regression methods such as CART, OLS and LASSO. Moreover, the scalability of our approach with respect to the size of the training sample is illustrated. Evolutionary algorithms (EAs) are naturally prone to parallel processing. However, when they are applied to data mining, the fitness calculations start to dominate and the typical population-based decomposition limits the parallel efficiency. When dealing with large-scale data, the scalable solution may become a real challenge. In this article, we propose a GPU-based parallelization of evolutionary induction of model trees. Such trees are a special case of decision tree (DT) that is designed to solve regression problems. The evolutionary approach allows not only a robust prediction but also to preserve the simplicity of DTs. However, the global approach is much more computationally demanding than state-of-the-art greedy inducers, and thus hard to apply to large-scale data mining directly. A parallelized induction of model trees (with univariate tests in the internal nodes and multiple linear regression models in the leaves) requires a carefully designed decomposition strategy. Six GPU-supported procedures are designed to successively: redistribute, sort and rearrange dataset samples, next, calculate models and fitness, and finally gather the results. Experimental validation is performed on real-life and artificial datasets, using various (low- and high-end) GPU accelerators. Results show that the GPU-supported solution enables time-efficient global induction of model trees on large-scale data, which until now was reserved for greedy methods. The obtained speedup is very satisfactory (even up to hundreds of times). The solution is scalable for datasets of different sizes and dimensions. The induction of decision trees is a widely-used approach to build classification models that guarantee high performance and expressiveness. Since a recursive-partitioning strategy guided for some splitting criterion is commonly used to induce these classifiers, overfitting, attribute selection bias, and instability to small training set changes are well-known problems in them. Other approaches, such as incremental induction, classifier ensembles, and the global search in the decision-tree-space, have been implemented to overcome these problems. In particular, metaheuristics such as simulated annealing, genetic algorithms, genetic programming, and ant colony optimization have been used to induce compact and accurate decision trees. This paper presents a state-of-the-art review of the use of single-solution-based metaheuristics and swarm and evolutionary computation algorithms to build decision trees as classification models. We outline the decision-tree-induction process components and detail the existing literature studies on metaheuristic-based approaches to building these classifiers. Several timelines showing the chronological order in which these approaches were introduced in the literature are included. A summary analysis of these studies is also conducted, focusing on their internal components and experimental studies. This work provides a useful reference point for future research in this field.},
  langid = {english},
  keywords = {Binary decision trees,computational complexity,NP-complete}
}

@book{intro2statslearning,
  title = {An {{Introduction}} to {{Statistical Learning}}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  date = {2013},
  series = {Springer {{Texts}} in {{Statistics}}},
  volume = {103},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4614-7138-7},
  url = {http://link.springer.com/10.1007/978-1-4614-7138-7},
  urldate = {2022-09-01},
  isbn = {978-1-4614-7137-0 978-1-4614-7138-7},
  keywords = {data mining,inference,R,R software,statistical learning,supervised learning,unsupervised learning}
}

@thesis{louppe2014,
  type = {phdthesis},
  title = {Understanding Random Forests: {{From}} Theory to Practice},
  author = {Louppe, Gilles},
  date = {2014-10},
  institution = {{University of Liege, Belgium}},
  url = {https://github.com/glouppe/phd-thesis},
  pagetotal = {225}
}

@article{moisescu-parejaa,
  title = {Lecture 2: {{Bellman}} Operator, {{Banach}}'s Fixed Point, Solving {{MDPs}} - {{SUMS}} 707 - {{Basic Reinforcement Learning}}},
  author = {Moisescu-Pareja, Gabriela and Nguyen, Viet},
  pages = {53},
  langid = {english}
}

@thesis{nadeemward2021,
  type = {mathesis},
  title = {Linear {{Programming}} in {{Reinforcement Learning}}},
  author = {Nadeem Ward, Patrick},
  date = {2021-04},
  institution = {{McGill University}},
  location = {{Montreal, Canada}},
  langid = {english},
  pagetotal = {73}
}

@book{puterman2014,
  title = {Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  shorttitle = {Markov Decision Processes},
  author = {Puterman, Martin L.},
  date = {2014-08-28},
  publisher = {{John Wiley \& Sons}},
  abstract = {The Wiley-Interscience Paperback Series consists of selected books that have been made more accessible to consumers in an effort to increase global appeal and general circulation. With these new unabridged softcover volumes, Wiley hopes to extend the lives of these works by making them available to future generations of statisticians, mathematicians, and scientists. "This text is unique in bringing together so many results hitherto found only in part in other texts and papers. . . . The text is fairly self-contained, inclusive of some basic mathematical results needed, and provides a rich diet of examples, applications, and exercises. The bibliographical material at the end of each chapter is excellent, not only from a historical perspective, but because it is valuable for researchers in acquiring a good perspective of the MDP research potential."\textemdash Zentralblatt fur Mathematik ". . . it is of great value to advanced-level students, researchers, and professional practitioners of this field to have now a complete volume (with more than 600 pages) devoted to this topic. . . . Markov Decision Processes: Discrete Stochastic Dynamic Programming represents an up-to-date, unified, and rigorous treatment of theoretical and computational aspects of discrete-time Markov decision processes."\textemdash Journal of the American Statistical Association},
  isbn = {978-1-118-62587-3},
  langid = {ngerman},
  pagetotal = {615},
  keywords = {Mathematics / General,Mathematics / Probability & Statistics / General,Mathematics / Probability & Statistics / Stochastic Processes}
}

@misc{raoRL4F,
  title = {Foundations of {{Reinforcement Learning}} with {{Applications}} in {{Finance}}},
  author = {Rao, Ashwin and Jelvis, Tikhon},
  date = {2022},
  publisher = {{Stanford University}},
  langid = {english}
}

@article{scikit-learn,
  title = {Scikit-Learn: {{Machine}} Learning in {{Python}}},
  author = {Pedregosa, Fabian and Varoquaux, Gael and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, M. and Duchesnay, Edouard},
  date = {2011},
  journaltitle = {Journal of Machine Learning Research},
  volume = {12},
  pages = {2825--2830}
}

@misc{silver2015,
  title = {Lectures on {{Reinforcement Learning}}},
  author = {Silver, David},
  date = {2015},
  annotation = {Published: \textsc{url:} https://www.davidsilver.uk/teaching/}
}

@misc{silver2017mastering,
  title = {Mastering {{Chess}} and {{Shogi}} by {{Self-Play}} with a {{General Reinforcement Learning Algorithm}}},
  author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
  date = {2017},
  annotation = {\_eprint: 1712.01815}
}

@article{silverchess,
  title = {A General Reinforcement Learning Algorithm That Masters Chess, Shogi, and {{Go}} through Self-Play},
  author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
  date = {2018},
  journaltitle = {Science},
  volume = {362},
  number = {6419},
  pages = {1140--1144},
  doi = {10.1126/science.aar6404},
  url = {https://www.science.org/doi/abs/10.1126/science.aar6404}
}

@inproceedings{sklearn_api,
  title = {{{API}} Design for Machine Learning Software: Experiences from the Scikit-Learn Project},
  booktitle = {{{ECML PKDD}} Workshop: {{Languages}} for Data Mining and Machine Learning},
  author = {Buitinck, Lars and Louppe, Gilles and Blondel, Mathieu and Pedregosa, Fabian and Mueller, Andreas and Grisel, Olivier and Niculae, Vlad and Prettenhofer, Peter and Gramfort, Alexandre and Grobler, Jaques and Layton, Robert and VanderPlas, Jake and Joly, Arnaud and Holt, Brian and Varoquaux, Ga\"el},
  date = {2013},
  pages = {108--122}
}

@article{survey-MDP-Apps,
  title = {A {{Survey}} of {{Applications}} of {{Markov Decision Processes}}},
  author = {White, D. J.},
  date = {1993},
  journaltitle = {The Journal of the Operational Research Society},
  volume = {44},
  number = {11},
  pages = {1073--1096},
  publisher = {{Palgrave Macmillan Journals}},
  issn = {01605682, 14769360}
}

@book{SuttonBarto,
  title = {Reinforcement Learning: {{An}} Introduction},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  date = {2020},
  series = {Adaptive {{Computation}} and {{Machine Learning}}},
  edition = {2},
  publisher = {{MIT press}},
  isbn = {978-0-262-03924-6}
}

@inproceedings{XGBoost,
  title = {{{XGBoost}}: {{A Scalable Tree Boosting System}}},
  shorttitle = {{{XGBoost}}},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Chen, Tianqi and Guestrin, Carlos},
  date = {2016-08-13},
  eprint = {1603.02754},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {785--794},
  doi = {10.1145/2939672.2939785},
  url = {http://arxiv.org/abs/1603.02754},
  urldate = {2022-09-05},
  abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning}
}

@article{xiong,
  title = {Learning {{Decision Trees}} with {{Reinforcement Learning}}},
  author = {Xiong, Zheng and Zhang, Wenpeng and Zhu, Wenwu},
  pages = {5},
  abstract = {Decision trees are usually learned by heuristic methods like greedy search, which only considers immediate information gain at the current splitting node and often results in sub-optimal solutions in a constrained search space. In this paper, to overcome this problem, we propose a reinforcement learning approach to automatically search for splitting strategies in the global search space based on the evaluation of long-term payoff. Empirically, decision trees generated by our method outperform those generated by commonly used greedy search methods under the same hyper-parameter setting.},
  langid = {english}
}